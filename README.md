# engineering-competition

###📖 프로젝트 소개### 
 본 프로젝트는 YOLOv5 딥러닝 모델을 사용하여 카메라 이미지 속 토마토의 익은 정도를 실시간으로 판별하고, 수확 대상('fully-ripe') 토마토의 중심 좌표를 아두이노(Arduino) 기반 로봇 팔에 전송하는 자동화 시스템입니다.
 카메라를 통해 인간의 눈을, AI 모델을 통해 두뇌를, 로봇 팔을 통해 손의 역할을 수행하여 스마트팜 환경에서 토마토 수확 과정을 자동화하는 것을 목표로 합니다.

###✨ 주요 기능###
 - **AI 기반 객체 탐지:** YOLOv5 모델을 이용해 토마토의 상태를 3단계(unripe, semi-ripe, fully-ripe)로 정밀하게 분류합니다.
 - **오프라인 환경 지원:** 인터넷 연결이 없는 온실이나 농장 환경에서도 안정적으로 작동하도록 source='local' 옵션을 사용하여 모델을 로드합니다.
 - **결과 시각화:** 탐지된 토마토의 위치, 클래스, 신뢰도를 경계 상자와 함께 표시한 이미지를 detection_result.png 파일로 저장하여 작동 결과를 직관적으로 확인할 수 있습니다.
 - **하드웨어 연동:** 계산된 좌표를 시리얼(Serial) 통신을 통해 아두이노로 전송하여 로봇 팔, 모터 등 외부 하드웨어를 제어할 수 있습니다.
 - **쉬운 설정:** 스크립트 상단에 주요 설정값(경로, 클래스 이름, 시리얼 포트 등)이 분리되어 있어 사용자 환경에 맞게 손쉽게 수정할 수 있습니다.

###📋하드웨어 요구사항###
 - PC 또는 라즈베리 파이
 - 웹캠 USB 타입
 - 아두이노 보드 
 - (선택) 로봇 팔 및 관련 모터/액추에이

###소프트웨어###
 - Python 3.8 이상
 - 필수 Python 라이브러리
    torch & torchvision
    opencv-python
    pyserial
    numpy
